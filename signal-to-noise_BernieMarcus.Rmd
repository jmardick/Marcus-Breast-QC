---
title: "Bernie Marcus Breast Signal-to-Noise Plots"
subtitle: "From 'Data for Classifier' Directory"
author: "`r Sys.info()[['user']]`"
date: "`r format(Sys.time(), '%B %d, %Y %H:%M')`"
knit: (function(inputFile, encoding) { 
      proj_name <- tools::file_path_sans_ext(basename(inputFile));
      out_dir <- paste0(proj_name, "_", Sys.Date());
      if(!file.exists(out_dir)) {   dir.create(out_dir) };
      rmarkdown::render(inputFile,
                        encoding=encoding, 
                        output_file=file.path(dirname(inputFile), 
                        out_dir, 
                        paste0(format(Sys.time(), "%Y-%m-%d_%H.%M"),"_", proj_name, ".html"))) 
                        })

output: 
  html_document:
    keep_md: yes
    df_print: paged
    toc: false
geometry: margin=0.5in
editor_options: 
  markdown: 
    wrap: 72
---

```{=html}
<style type="text/css">
.main-container {
max-width: 1600px;
margin-left: auto;
margin-right: auto;
}
</style>
```

```{css, echo=FALSE}
h1,h2, h3, h4, h5, p {
text-align: center;
font-size: 20px;
}
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, echo = FALSE, cache = FALSE, results = "hold")
```

```{r libraries, message = FALSE, warning = FALSE}
library(rmarkdown)
library(knitr)
library(kableExtra)
library(ggpubr)

library(tidyverse)
library(ggthemes)
library(reshape2)
library(readxl)
library(rawrr)
library(sqldf)
library(readr)

library(stringr)
library(doParallel)
library(fcluster)
library(johnfuncs)
```

```{r user input}
## Full path to folder with sample files (excel or csv, or raw Thermo files)
## PASTE PATH IN BETWEEN INNER PARENTHASIS WITH QUOTES ON THE OUTSIDE -- NO NEED TO CHANGE BACKSLASHES TO FORWARD SLASHES
sample_dir <- gsub("\\\\", "/", r"(C:\Users\Jacob\Box\Eberlin_Lab_BCM\Projects\Breast MSPEN_Marcus Foundation\Data for Classifier)")
#sample_dir <- gsub("\\\\", "/", r"(/Users/jacobmardick/Library/CloudStorage/Box-Box/Eberlin_Lab_BCM/Projects/Breast MSPEN_Marcus Foundation/Data for Classifier)")

## Full path to feature list, otherwise NULL
## TODO: add functionality for csv feature lists
#feature_file <- gsub("\\\\", "/", r"(C:\Users\Jacob\Documents\Breast-BernieMarcus\20250218_QC-metric-feature-list.xlsx)")
feature_file <- NULL

## Full path to background peak list, otherwise NULL
## TODO: add functionality for xlsx background files
#background_file <- gsub("\\\\", "/", r"(C:\Users\fjackobs\BACKGROUND_FILE.csv)")
background_file <- NULL

## ---------------------------------------------------------------------------

## Scan numbers to import when using raw Thermo files
scans <- 50:500 ## number of scans to extract from each raw file

## Mass range to filter
mass_range <- c(100,1000)

## Peak Alignment Method: "clustering", "binning", or "featurelist"
peak_alignment_method <- "clustering"

## If peak alignment method is "clustering":
clust_h <- 0.05 ## Height at which to cut dendrogram to determine clusters

## If peak alignment method is "featurelist":
ppm_error <- 5 ## Mass error tolerance of sample peaks to match to feature peaks

## Normalization Method: "tic", "maxpeak", "median", "medianlog", or "none"
normalization_method <- "tic"

## Target m/z values of interest for QC metrics
target_mz <- c(145.05, 175.03, 215.03, 303.23, 327.23, 750.54, 810.53, 885.55)
```

```{r create directory for output files, include = FALSE}
proj_name <- tools::file_path_sans_ext(basename(rstudioapi::getSourceEditorContext()$path))

out_dir <- paste0(proj_name, "_", Sys.Date())

if(!file.exists(out_dir)) {   dir.create(out_dir) }

files_dir <- paste0(format(Sys.time(), "%Y-%m-%d_%H.%M"), "_", proj_name, "_files")

if(!file.exists(file.path(out_dir,files_dir))) {   dir.create(file.path(out_dir,files_dir)) }
```

```{r classes}
## read sub-directories for class names
classes <- basename(list.dirs(sample_dir, recursive=FALSE))

## fixed objects for exporting to parallel computing
fixed_objects <- list(scans = scans, mass_range = mass_range)
```

```{r file extension}
## check file extension
sample_file_ext <- unique(unlist(
  lapply(classes, function(x) 
    tools::file_ext(list.files(file.path(sample_dir, "/",x,"/"))))))[1]
```

```{r file and sample names}
## file names
file_name_list <- lapply(classes, function(x) 
  list.files(path = file.path(sample_dir,x), pattern = paste0("*.", sample_file_ext), full.names = TRUE))

## Ensure patient ordering is consistent across different OSes.
file_name_list <- lapply(file_name_list, sort)

## sample names
sample_names_list <- lapply(file_name_list, function(x) tools::file_path_sans_ext(basename(x)))
names(sample_names_list) <- classes
sample_names <- unlist(sample_names_list)
sample_names_df <- purrr::map_df(sample_names_list, ~as.data.frame(.x), .id="id")
colnames(sample_names_df) <- c("class", "sample_name")
```

```{r csv data}
if (sample_file_ext == "csv") {
  
  process_csv <- function(file_name_list, fixed_objects) {
    cl <- makeCluster(detectCores() - 1) # Use one less than the number of available cores
    registerDoParallel(cl)
    
    clusterEvalQ(cl, {
      library(dplyr)
      library(purrr)
    })
    
    result <- foreach(i = seq_along(file_name_list), .packages = c('dplyr', 'purrr', 'tidyverse')) %:% 
      foreach(j = seq_along(file_name_list[[i]])) %dopar% {
        
        ## extract m/z and intensity into list of lists
        spectrum <- tryCatch(read_csv(file_name_list[[i]][[j]], 
                                      col_names = c("mass", "intensity"),
                                      skip = 6), 
                             error = function(e) tryCatch(read_csv(file_name_list[[i]][[j]], 
                                                                   col_names = c("mass", "intensity", "SNR"),
                                                                   skip = 6),
                                                          error = function(e) return(read_csv(file_name_list[[i]][[j]], 
                                                                                              col_names = c("mass", "intensity", "relative", "noise"),
                                                                                              skip = 6))))
        
        ## Round m/z values to 3 decimal places
        spectrum$mass <- round(as.numeric(spectrum$mass, 3))
        
        ## FILTER #1: RETAIN PEAKS WITHIN MASS RANGE
        spectrum <- spectrum[spectrum$mass >= fixed_objects$mass_range[1] & spectrum$mass <= fixed_objects$mass_range[2], ]
        
        ## FILTER #2: RETAIN PEAKS WITH SNR >= 3
        spectra_list <- if(length(spectrum) == 4) {
          ## Add SNR column
          spectrum$SNR <- (spectrum$intensity)/(spectrum$noise)
          
          spectrum <- tryCatch(subset(spectrum, SNR >= 3),
                               error = function(e) return(spectrum))
          
          ## Remove columns "relative", "noise", and "SNR"
          spectrum <- subset(spectrum, select = -c(relative, noise, SNR))
          
          return(spectrum)
        }else if(length(spectrum) == 3){
          ## Remove column "relative"
          spectrum <- spectrum[, !colnames(spectrum) %in% c("X3")]
          
          return(spectrum)
        }else if(length(spectrum) == 2){
          return(spectrum)
        }
      }
    
    stopCluster(cl)
    return(result)
  }
  
  spectra_list <- process_csv(file_name_list, fixed_objects)
  
  ## Set sample names and classes of spectra_list
  spectra_list <- lapply(seq_along(spectra_list), \(i) setNames(spectra_list[[i]], sample_names_list[[i]]))
  names(spectra_list) <- classes
}
```

```{r excel data}
if (sample_file_ext == "xlsx") {
  
  process_xlsx <- function(file_name_list, fixed_objects) {
    cl <- makeCluster(detectCores() - 1) # Use one less than the number of available cores
    registerDoParallel(cl)
    
    clusterEvalQ(cl, {
      library(dplyr)
      library(readxl)
      library(purrr)
    })
    
    result <- foreach(i = seq_along(file_name_list), .packages = c('dplyr', 'readxl', 'purrr')) %:% 
      foreach(j = seq_along(file_name_list[[i]])) %dopar% {
        
        ## extract m/z and intensity into list of lists
        spectrum <- tryCatch(read_excel(file_name_list[[i]][[j]], 
                                        col_names = c("mass", "intensity"), 
                                        skip = 8), 
                             error = function(e) tryCatch(read_excel(file_name_list[[i]][[j]], 
                                                                     col_names = c("mass", "intensity", "relative"), 
                                                                     skip = 8),
                                                          error = function(e) return(read_excel(file_name_list[[i]][[j]], 
                                                                                                col_names = c("mass", "intensity", "relative", "noise"), 
                                                                                                skip = 8))))
        
        ## Round m/z values to 3 decimal places
        spectrum$mass <- round(spectrum$mass, 3)

        ## FILTER #1: RETAIN PEAKS WITHIN MASS RANGE
        spectrum <- spectrum[spectrum$mass >= fixed_objects$mass_range[1] & spectrum$mass <= fixed_objects$mass_range[2], ]
        
        ## FILTER #2: RETAIN PEAKS WITH SNR >= 3
        spectra_list <- if(length(spectrum) == 4) {
          ## Add SNR column
          spectrum$SNR <- (spectrum$intensity)/(spectrum$noise)
          
          spectrum <- tryCatch(subset(spectrum, SNR >= 3),
                               error = function(e) return(spectrum))
          
          ## Remove columns "relative", "noise", and "SNR"
          spectrum <- subset(spectrum, select = -c(relative, noise, SNR))
          
          return(spectrum)
        }else if(length(spectrum) == 3){
          ## Remove column "relative"
          spectrum <- spectrum[, !colnames(spectrum) %in% c("relative")]
          
          return(spectrum)
        }else if(length(spectrum) == 2){
          return(spectrum)
        }
      }
    
    stopCluster(cl)
    return(result)
  }
  
  spectra_list <- process_xlsx(file_name_list, fixed_objects)
  
  ## Set sample names and classes of spectra_list
  spectra_list <- lapply(seq_along(spectra_list), \(i) setNames(spectra_list[[i]], sample_names_list[[i]]))
  names(spectra_list) <- classes
}
```

```{r raw Thermo data}
## If sample files are raw Thermo
if (sample_file_ext == "raw") {
  
  process_raw_thermo <- function(file_name_list, fixed_objects) {
    cl <- makeCluster(detectCores() - 1) # Use one less than the number of available cores
    registerDoParallel(cl)
    
    clusterEvalQ(cl, {
      library(dplyr)
      library(rawrr)
      library(purrr)
    })
    
    result <- foreach(i = seq_along(file_name_list), .packages = c('dplyr', 'rawrr', 'purrr')) %:% 
      foreach(j = seq_along(file_name_list[[i]])) %dopar% {
        
        ## Raw Thermo Data
        raw_data <- readSpectrum(file_name_list[[i]][[j]], scan = fixed_objects$scans)
        
        ## only keep relevant fields (mass, intensity, and noise) for each spectra
        ## round mass to 3 decimal places b/c mass accuracy of instrument is ~ 1 ppm or 4 b/c that's what Thermo reports?
        spectrum <- lapply(raw_data, function(x)
          tryCatch(data.frame(mass = round(x$centroid.mZ, 3),
                              intensity = x$centroid.intensity,
                              noise = x$noise,
                              SNR = ((x$centroid.intensity)/(x$noises))),
                   error = function(e) return(data.frame(mass = round(x$centroid.mZ, 3),
                                                         intensity = x$centroid.intensity,
                                                         noise = x$centroid.PreferredNoises,
                                                         SNR = ((x$centroid.intensity)/(x$centroid.PreferredNoises))
                   )
                   )
          )
        )
        
        ## FILTER #1: RETAIN PEAKS WITHIN MASS RANGE
        spectrum <- lapply(spectrum, function(x) x[x$mass >= fixed_objects$mass_range[1] & x$mass <= fixed_objects$mass_range[2], ])
        
        ## FILTER #2: RETAIN PEAKS WITH SNR >= 3
        spectrum <- lapply(spectrum, function(x)
          tryCatch(subset(x, SNR >= 3),
                   error = function(e) return(x)))
        
        ## FILTER #2b: RETAIN SCANS WITH >= 50 peaks
        spectrum <- Filter(function(z) nrow(z) >= 50, spectrum)
        
        ## Aggregate (sum) intensities of any peaks within scans that are duplicated due to rounding to 3 decimal places
        spectrum <- lapply(spectrum, function(x) aggregate(intensity ~ mass, data = x, FUN = sum))
        
        ## Merge scans into one spectrum per sample
        spectrum <- spectrum %>%
          reduce(full_join, by = "mass") %>%
          select(mass, matches("intensity"))
        
        ## Replace NA with 0
        spectrum <- replace(spectrum, is.na(spectrum), 0)
        
        ## Aggregate intensities of duplicate masses 
        ## AVERAGE INTENSITIES AS DONE IN THERMO FREESTYLE SOFTWARE (including zero values)
        spectrum <- data.frame(cbind(spectrum[, "mass"],
                                     tryCatch(rowMeans(spectrum[, !names(spectrum) %in% c("mass")]),
                                              error = function(e) return(spectrum[, "intensity"]))))
        
        ## Rename columns to mass and intensity
        colnames(spectrum) <- c("mass", "intensity")
        
        ## Order m/z smallest to largest
        spectrum <- spectrum[order(spectrum$mass), ]
      }
    
    stopCluster(cl)
    return(result)
  }
  
  spectra_list <- process_raw_thermo(file_name_list, fixed_objects)
  
  ## Set sample names and classes of spectra_list
  spectra_list <- lapply(seq_along(spectra_list), \(i) setNames(spectra_list[[i]], sample_names_list[[i]]))
  names(spectra_list) <- classes
}
```

``` {r peak alignment clustering}
## If peak alignment method is clustering
if (peak_alignment_method == "clustering") {
  
  clust_int_method  <-  "sumints" ## Handling of multiple intensities aggregating to one cluster centroid: "sumints" or "maxint"
  
  ## If background peak list: add background peaks to clustering
  if (!is.null(background_file)) {
    bg_mz <- unlist(read.csv(background_file, header = FALSE))
    
    sample_mz <- sort(unlist(
      lapply(spectra_list, function(y)
        lapply(y, function(x)
          round(x$mass, 3)))))
    
    all_mz <- c(bg_mz, sample_mz)
    names(all_mz) <- all_mz
    
  } else { ## If no background peak list
    all_mz <- sort(unlist(
      lapply(spectra_list, function(y)
        lapply(y, function(x)
          round(x$mass, 3)))))
    
    names(all_mz) <- all_mz
  }
  
  ## Cluster peaks into centroids
  tree <- fcluster(all_mz)
  clust_mz <- fcutree(all_mz, tree, h=clust_h)
  clustMZ <- sort(clust_mz$cen)
  
  ## Match cluster centroids to sample peaks
  clusterMatrixList <- lapply(spectra_list, function(x, y, z, w) 
    get_cluster_matrix(x, y, z, w), y=clustMZ, z = clust_h, w = clust_int_method)
  
  preprocList <- lapply(clusterMatrixList, function(x) as.matrix(get_data_matrix_clustering(x)))
  
  aligned_spectra <- do.call(rbind, preprocList)
  
  colnames(aligned_spectra) <- clustMZ
  rownames(aligned_spectra) <- sample_names
  
  ## FILTER #3: REMOVE RARE/UNCOMMON PEAKS PRESENT < 10% SAMPLES
  mz_count_filter <- colSums(aligned_spectra != 0) > as.integer(nrow(aligned_spectra)*0.10)
  aligned_spectra <- aligned_spectra[, mz_count_filter]
  
  filtered_mz <- clustMZ[mz_count_filter]
  
  ## FILTER #4: REMOVE BACKGROUND PEAKS (IF BACKGROUND FILE PRESENT)
  if (!is.null(background_file)) {
    
    ## match bg_mz to cluster centroid
    temp_a <- data.frame(cluster_id = clust_mz$cluster_index,
                         all_mz = all_mz)
    
    temp_b <- data.frame(clust_centroid = clust_mz$centroid, 
                         cluster_id = unique(clust_mz$cluster_index)[order(unique(clust_mz$cluster_index))])
    
    temp_c <- merge(temp_a, temp_b, by = "cluster_id")
    
    bg_centroids <- unique(temp_c[temp_c$all_mz %in% bg_mz, ])
    
    ## Remove peaks from aligned_spectra that are in bg_mz_centroid
    ## CHANGE THIS SO ITS NOT LOOKING IN COLUMN NAMES BECAUSE THOSE ARE CHARACTERS AND NOT NUMERIC WHICH MESSES STUFF UP
    aligned_spectra <- aligned_spectra[, !(colnames(aligned_spectra) %in% bg_centroids$clust_centroid)]
    
    filtered_mz <- as.numeric(colnames(aligned_spectra))
  }
  
  ## which peaks make up a cluster
  ## Cluster indexes
  cluster_index <- data.frame(clust_mz$cluster_index)
  colnames(cluster_index) <- c("cluster")
  
  ## Attach cluster_index and all_mz
  mz_cluster_index <- cbind(cluster_index, all_mz)
  
  ## Average m/z values in same cluster to calculate centroid m/z value
  mz_centroid <- data.frame(cluster = seq(1:length(clust_mz$centroid)), centroid = clust_mz$centroid)
  
  ## Join centroids to original mz values
  mz_cluster_index <- merge(mz_cluster_index,
                            mz_centroid,
                            by = "cluster",
                            all = TRUE)
  
  colnames(mz_cluster_index) <- c("cluster","mass","centroid")
  
  ## Remove duplicate rows of same cluster, mz, and centroid
  mz_cluster_index <- mz_cluster_index[!duplicated(mz_cluster_index), ]
  
  ## min and max for each centroid
  centroid_min_max <- mz_cluster_index %>%
    group_by(cluster) %>%
    summarise(
      centroid = first(centroid),
      min_mass = min(mass),
      max_mass = max(mass)
    )
  
  ## only keep filtered_mz in min_max_clusters df
  centroid_min_max <- centroid_min_max[which(centroid_min_max$centroid %in% filtered_mz), ]
}
```

```{r peak alignment binning}
if (peak_alignment_method == "binning") {
  ## Hard coded that m/z values are rounded to 2 decimal places and intensities of peaks that fall into the same bin are summed (by John Lin). 
  ## TBD about changing this - FEJ 2024-09-06
  
  all_mz <- round(sort(unlist(
    lapply(spectra_list, function(y)
      lapply(y, function(x)
        x$mass)))), 2) ## round to 2 decimal places
  
  names(all_mz) <- all_mz
  
  ## FILTER #3: REMOVE RARE/UNCOMMON PEAKS PRESENT < 10% SAMPLES
  mz_count <- table(all_mz)
  mz_count_filter <- mz_count > as.integer(length(sample_names)*0.10)
  filtered_mz <- as.numeric(names(mz_count)[mz_count_filter])
  
  ## Bin sample peaks
  preprocList <- lapply(spectra_list, function(x,z) get_data_matrix_binning(x,z), z=filtered_mz)
  
  aligned_spectra <- do.call(rbind, preprocList)
  
  colnames(aligned_spectra) <- filtered_mz
  rownames(aligned_spectra) <- sample_names
  
  ## FILTER #4: REMOVE BACKGROUND PEAKS (IF BACKGROUND FILE PRESENT)
  if (!is.null(background_file)) {
    bg_mz <- round(unlist(read.csv(background_file, header = FALSE)), 2) ## round to 2 decimal places for binned values
    aligned_spectra <- aligned_spectra[, !(colnames(aligned_spectra) %in% bg_mz)]
    
    filtered_mz <- as.numeric(colnames(aligned_spectra))
  }
}
```

```{r peak alignment feature list}
if (peak_alignment_method == "featurelist") {
  
  if (is.null(feature_file)) {
    
    print("No path specified for feature list. Add path to file or choose a different peak alignment method.")
    
  }else{

    ## Read file with feature peaks
    feature_peaks <- unlist(read_excel(feature_file, col_names = FALSE))
    ## TODO: What if CSV file?
    
    ## Feature mz plus/minus instrument mass error, round to 3 decimal places
    mass_error <- unlist((ppm_error * feature_peaks)/1e6)
    
    feature_peaks <- data.frame(feature_mass = feature_peaks,
                                mass_error = mass_error,
                                mass_error_lower = round(feature_peaks - mass_error,3),
                                mass_error_upper = round(feature_peaks + mass_error,3))
    
    ## Reset rownames
    rownames(feature_peaks) <- NULL
    
    ## fixed objects for exporting to parallel computing
    fixed_objects <- list(scans = scans, mass_range = mass_range, feature_peaks = feature_peaks)
    
    feature_peak_alignment <- function(spectra_list, fixed_objects) {
      cl <- makeCluster(detectCores() - 1) # Use one less than the number of available cores
      registerDoParallel(cl)
      
      clusterEvalQ(cl, {
        library(dplyr)
        library(sqldf)
      })
      
      #clusterExport(cl, list("feature_peaks"))
      
      result <- foreach(i = seq_along(spectra_list), .packages = c('dplyr', 'sqldf')) %:% 
        foreach(j = seq_along(spectra_list[[i]])) %dopar% {
          
          spectrum <- spectra_list[[i]][[j]]
          feature_peaks <- fixed_objects$feature_peaks
          
          feature_matched_spectrum <- sqldf("SELECT feature_peaks.feature_mass, spectrum.*
          FROM spectrum,feature_peaks
          WHERE spectrum.mass between feature_peaks.mass_error_lower AND feature_peaks.mass_error_upper")
          
          ## remove mass columns
          feature_matched_spectrum <- subset(feature_matched_spectrum, select = -c(mass))
          
          ## sum intensities of duplicates
          feature_matched_spectrum <- aggregate(intensity ~ ., data = feature_matched_spectrum, FUN = sum)
        }
      stopCluster(cl)
      return(result)
    }
    
    feature_matched_spectra <- feature_peak_alignment(spectra_list, fixed_objects)
    
    ## turn list of lists into dataframe
    feature_matched_spectra <- lapply(feature_matched_spectra, function(x) x %>%
                                        reduce(full_join,by = "feature_mass")) %>% reduce(full_join,by = "feature_mass")
    
    ## sort by target_mz
    feature_matched_spectra <- feature_matched_spectra[order(feature_matched_spectra$feature_mass), ]
    
    ## feature_mass column to rownames
    feature_matched_spectra <- feature_matched_spectra %>% 
      remove_rownames %>% 
      column_to_rownames(var = "feature_mass") %>% 
      as.data.frame()
    
    ## Add sample names as column names
    colnames(feature_matched_spectra) <- sample_names
    
    ## Replace NA with 0
    feature_matched_spectra <- replace(feature_matched_spectra, is.na(feature_matched_spectra), 0)
    
    ## Transpose so rows are samples and columns are masses
    aligned_spectra <- t(feature_matched_spectra)
    
    filtered_mz <- as.numeric(colnames(aligned_spectra))
  }
}
```

```{r normalization}
xall <- normalize_pixel(aligned_spectra, normalization_method)
```

```{r yall}
## create yall object 
yall <- foreach(i = 1:length(file_name_list), .combine = c) %do% {
  rep(i, length(file_name_list[[i]])) }

## factorize yall
yall <- factor(yall,levels=c("1","2"),labels = classes)
```

```{r extract mz}
## Convert xall to data frame
xall_df <- as.data.frame(xall)
xall_df$Sample <- rownames(xall_df)

## Convert to long format for ggplot
xall_long <- xall_df |> 
  pivot_longer(cols = -Sample, names_to = "mz", values_to = "Intensity") |> 
  mutate(mz = as.numeric(mz))

tolerance <- 0.05

## Extract desired peaks
xall_filtered <- xall_long |> 
  group_by(Sample) |> 
  reframe(
    target_mz = rep(target_mz, each = 1),
    closest_mz = map_dbl(target_mz, function(t) {
       nearest_mz <- mz[which.min(abs(mz - t))]
       if (abs(nearest_mz - t) <= tolerance) return(nearest_mz) else return(NA_real_)  # Ensure NA for out-of-tolerance matches
    }),
    Intensity = map_dbl(target_mz, function(t) {
      nearest_index <- which.min(abs(mz - t))
      if (abs(mz[nearest_index] - t) <= tolerance) return(Intensity[nearest_index]) else return(NA_real_)
    })
  ) |> 
  filter(!is.na(closest_mz))

## Include class label from sample_names_df
xall_filtered <- xall_filtered |> 
  left_join(sample_names_df, by = c("Sample" = "sample_name"))

## Unique m/z values
unique_mz <- unique(xall_filtered$target_mz)
```

```{r plots}
colorblind_palette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7", "#999999")

## Box plot of m/z vs Intensity across all samples
#ggplot(xall_filtered, aes(x = factor(target_mz), y = Intensity, fill = factor(target_mz))) +
  #geom_boxplot(outlier.shape = NA) +
  #geom_jitter(color = "black", width = 0.2, alpha = 0.2, size = 1.5) +
  #scale_fill_manual(values = colorblind_palette) +
  #theme_minimal() +
  #labs(title = "Distribution of Intensities for Selected m/z Values",
       #x = "m/z",
       #y = "Raw Intensity",
       #fill = "m/z") +
  #theme(axis.text.x = element_text(angle = 45, hjust = 1))

## Separate plots of Sample vs Intensity for each target m/z value
## Loop through each m/z and generate a separate plot
for (mz in unique_mz) {
  ## Filter data for this specific m/z
  xall_subset <- xall_filtered |> 
    filter(target_mz == mz)
  
  ## Sort samples by class (ie tumor or normal)
  xall_subset <- xall_subset |> 
    arrange(class, Sample)
  
  ## Position to draw divider between Normal and Cancer in Plot
  divider_position <- sum(xall_subset$class == "Normal") + 0.5
  
  ## Generate plot
  plot <- ggplot(xall_subset, aes(x = Sample, y = Intensity)) +
    ## Background shading
    annotate("rect", # Normal (blue)
             xmin = 0, 
             xmax = divider_position - 0.5, 
             ymin = -Inf, 
             ymax = Inf, 
             fill = "lightblue", 
             alpha = 0.3) + 
    annotate("rect", # Cancer (red)
             xmin = divider_position, 
             xmax = Inf, 
             ymin = -Inf, 
             ymax = Inf, 
             fill = "lightcoral", 
             alpha = 0.3) +
    geom_vline(xintercept = divider_position, # Divider line
               linetype = "dashed", 
               color = "black") +
    geom_point(color = "black", # Scatter points
               size = 2, 
               alpha = 0.7) +
    geom_line(aes(group = 1), color = "gray") +
    annotate("text", 
             x = divider_position / 2, 
             y = max(xall_subset$Intensity, na.rm = TRUE) * 1.1, 
             label = "Normal",
             color = "blue",
             size = 5,
             fontface = "bold") +
    annotate("text", 
             x = divider_position + (nrow(xall_subset) - divider_position) / 2, 
             y = max(xall_subset$Intensity, na.rm = TRUE) * 1.1,
             label = "Cancer",
             color = "red",
             size = 5,
             fontface = "bold") +
    theme_minimal() +
    labs(title = paste("Intensities for m/z", mz),
         x = "Sample",
         y = "TIC Normalized Intensity") +
    theme(axis.text.x = element_blank(),
          plot.title = element_text(hjust = 0.5, face = "bold", size = 16),
          axis.title.x = element_text(size = 14, face = "bold"),
          axis.title.y = element_text(size = 14, face = "bold"),
          axis.text.y = element_text(size = 12))
  
  print(plot)
  
  ## Save each plot
  plot_filename <- paste0(proj_name, "_mz_", mz, "_scatter-plot.png")
  ggsave(filename = file.path(out_dir, files_dir, plot_filename), plot = plot, width = 8, height = 6, dpi = 300)
}
```

<br>

#### **Preprocessing and Statistical Model Settings**

```{r chunk3, fig.align = "center"}
if (peak_alignment_method == "clustering") {
  cluster_bin_size <- c("Cluster Height:", clust_h)
} else if (peak_alignment_method == "binning") {
  cluster_bin_size <- c("Bin Size:", "0.01")
} else if (peak_alignment_method == "featurelist") {
  cluster_bin_size <- c("Feature Mass Error (ppm):", ppm_error)
}

if (is.null(background_file)) {
  bg_exclusion <- "no"
} else if (!is.null(background_file)) {
  bg_exclusion <- "yes"
}

settings_df <- rbind(c("Mass Range (m/z):", paste0(mass_range[1], " - ", mass_range[2])),
                     c("Peak Alignment Method:", peak_alignment_method),
                     cluster_bin_size,
                     c("Background Peak Exclusion:", bg_exclusion),
                     c("Normalization Method:", normalization_method))

kable(settings_df,
      row.names = FALSE,
      align = "l",
      format = "html",
      escape = FALSE)%>%
  column_spec(1:2, width = "3in")%>% 
  kable_styling(full_width = FALSE, 
                font_size = 14)
```

```{r R data, include = FALSE}
save(list = ls(), 
     file=file.path(out_dir, files_dir, paste0(format(Sys.time(), "%Y-%m-%d_%H.%M"), "_", proj_name,"_preprocessed.RData")))
```

<br>

#### **Session Info**

```{r}
sessionInfo()
```